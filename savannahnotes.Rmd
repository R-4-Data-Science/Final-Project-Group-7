---
title: "savannahnotes"
output: html_document
---
```{r}
adult_csv <- read.csv("/Users/srascon/Downloads/6210/git/HW2_Group14/adult.csv", sep = ";")
adult <- data.frame(adult_csv)
adult <- adult[,-1]

# change character columns to factor
adult$workclass <- as.factor(adult$workclass)
adult$education <- as.factor(adult$education)
adult$marital.status <- as.factor(adult$marital.status)
adult$occupation <- as.factor(adult$occupation)
adult$relationship <- as.factor(adult$relationship)
adult$race <- as.factor(adult$race)
adult$sex <- as.factor(adult$sex)
adult$native.country <- as.factor(adult$native.country)
adult$NA. <- as.factor(adult$NA.)

```

Section 3.2
```{r}

stability <- function(data, response, B = 100, K = 5, epsilon = 1e-6, 
                           delta = 2, L = 25, model_type = NULL) {
  
  result_matrix <- matrix(0, nrow = B, ncol = length(setdiff(names(data), response)),
                          dimnames = list(NULL, setdiff(names(data), response)))
  
  resampling <- vector("list", B)
  predictors <- colnames(result_matrix)
  p_length <- length(predictors)
  
  for (b in 1:B) {
    # Bootstrap
    index_b <- sample(1:nrow(data), size = nrow(data), replace = TRUE)
    data_b <- data[index_b, , drop = FALSE]
    
    # Fit model
    models_b <- build_paths(data_b, response,
                            K = K, epsilon = epsilon,
                            delta = delta, L = L,
                            model_type = model_type)
    
    # Feature inclusion
    counts <- rep(0, p)
    names(counts) <- predictors
    if (length(models_b) > 0) {
      for (m in models_b) counts[m$variables] <- counts[m$variables] + 1
    }
    
    # Proportions for Bootstrap sample
    z_j_b <- counts / (ifelse(length(models_b) > 0, length(models_b), 1)) # calculates ( z_j^{(b)} )
    result_matrix[b, ] <- z_j_b
    
    # Store proportions
    resampling [[b]] <- z_j_b
  }
  
  # Calculate stability
  pi <- colMeans(result_matrix)
  path_stability <- data.frame(variable = predictors, pi = pi)
  path_stability <- path_stability[order(-path_stability$pi), ]
  
  return(list(path_stability = path_stability, resampling = resampling))
}
```

Savannah's edits to build paths:
```{r}
# Edit build paths
X = adult[,1:14]
response = adult[,15]

path_forest <- build_paths(X = adult[,1:14], response = adult[,15])

build_paths <- function(X, response, K = 5, epsilon = 10, delta = 200, L = 25, model_type = NULL){

  # --- Auto-detect model type ---
  detect_model_type <- function(response) {
    y <- response
    if (is.factor(y) || length(unique(y)) == 2) return("logistic")
    if (is.numeric(y)) return("linear")
    stop("Cannot detect model type automatically.")
  }

  if (is.null(model_type)) {
    model_type <- detect_model_type(response)
    cat("Detected model type:", model_type, "\n")
  }

  predictors <- colnames(X)
  response_name <- "response"

  # --- Model fitting helper ---
  fit_model <- function(vars) {
    formula_str <- paste(response_name, "~",
                         ifelse(length(vars) == 0, "1", paste(vars, collapse = "+")))
    if (model_type == "linear") {
      return(lm(as.formula(formula_str), data = X))
    } else {
      return(glm(as.formula(formula_str), data = X, family = binomial))
    }
  }
  
  # --- Start with null model ---
  null_fit <- fit_model(character())
  null_aic <- AIC(null_fit)
  null_vars <- c()
  
  # all_models is a list that contains lists for each set of models. The first list set is an entry for the null model which only contains the intercept.
  all_models <- list(list(variables = names(null_fit$coefficients), fit = null_fit, AIC = null_aic))
  
  start_models <- list()
  start_aic <- list()
  
  k <- 1
  frontiers <- list()
  aic_by_model <- list()
    
    for (a in 1:K) {
      
      if(k == 1){
        
        start_fit <- list()
        
        # make 1 predictor models
        for(i in 1:length(predictors)){
        
        suppressWarnings({
          start_fit[[i]] <- try(fit_model(predictors[i]), silent = TRUE)
        })
        if (inherits(start_fit[[i]], "try-error")) next
        
        # calculate AIC for 1 predictor models
        start_aic[i] <- AIC(start_fit[[i]])
        
        }
        
        # save info for 1 predictor models, add to total model list, move to k = 2
        start_models <- list(variables = predictors, fit = start_fit, AIC = start_aic)
       
        frontiers[[k]] <- start_models$variables
        aic_by_model[[k]] <- start_aic
        
         k <- k+1
        
      } else if(k == 2){
        
      # takes the variables from the 1 variables models
      current_vars <- start_models$variables
  
      vars_diff <- list()
      child_combos <- list()
      
      # determine sets of variables that make up the child combinations for this dimension
      for(b in 1:length(current_vars)){
      
      # this identifies the new variables that need to be added one by one to each model
      vars_diff[[b]] <- setdiff(predictors, current_vars[b])
      
      # for each parent model, make a list of new combinations that add one more variable
      child_combos[[b]] <- lapply(vars_diff[[b]], function(x) append(x, current_vars[b]))
      }
      
      # make a list to contain child models
      child_fit <- list()
      
      # make a list to contain child AIC
      child_fit_aic <- list()
      
      # models retained after comparison to parent
      child_retain <- list()
      
      for(b in 1:length(child_combos)){
        
        # fit child models for each parent model
        child_fit[[b]] <- lapply(child_combos[[b]], fit_model)
        
        # calculate AIC for each child model
        child_fit_aic[[b]] <- lapply(child_fit[[b]], AIC)
        
      }
      
        # make a list of each minimum aic for each set of models to use for filter
        child_min <- list()
        for(b in 1:length(child_fit_aic[[b]])){
          
        child_min[[b]] <- min(as.numeric(child_fit_aic[[b]]))
       
         }
        
        # compare AIC between child models and parent models
      extract_child_aic <- lapply(child_fit_aic, function(x) rep(NA, length(x)))

      for(b in seq_along(child_fit_aic)){
      for(c in seq_along(child_fit_aic[[b]])){
    
        
    aic_value  <- as.numeric(child_fit_aic[[b]][[c]])     # FIX
    min_value  <- as.numeric(child_min[[b]])
    start_val  <- as.numeric(start_aic[b])
    
    if(aic_value <= (min_value + delta) &&
       aic_value <= (start_val - epsilon)) {
      
      extract_child_aic[[b]][c] <- aic_value
         }
        }
      }
      
      extract_fit <- vector("list", length(child_fit_aic))
      extract_combos <- vector("list", length(child_fit_aic))

      for(b in seq_along(child_fit_aic)) {
  
      # Find which AICs passed your threshold
      keep_idx <- which(!is.na(extract_child_aic[[b]]))
  
      # Extract the models at the same positions
      extract_fit[[b]] <- child_fit[[b]][keep_idx]
      # Keep combos at the same positions
      extract_combos[[b]] <- child_combos[[b]][keep_idx]
      
      }
      
      extract_aic <- vector("list", length(child_fit_aic))
      extract_aic <- lapply(extract_child_aic, function(x) x[!is.na(x)])
      
      frontiers[[k]] <- extract_combos
      aic_by_model[[k]] <- extract_aic
      
      } else { #for dimensions greater than 2 
        
        # takes the variables from the extracted 2 variables models
      current_combos <- extract_combos
  
      vars_diff <- vector("list", length(current_combos))
      child_combos <- vector("list", length(current_combos))
      
      # determine sets of variables that make up the child combinations for this     dimension

      for(b in seq_along(current_combos)){
      
      child_combos[[b]] <- vector("list", length(current_combos[[b]]))
      vars_diff[[b]] <- vector("list", length(current_combos[[b]]))
  
      for(c in seq_along(current_combos[[b]])){
    
        parent_vars <- current_combos[[b]][[c]]   
        
        vars_diff[[b]][[c]] <- setdiff(predictors, parent_vars)
    
        # for each parent model, make a list of new combinations that add one more variable
        child_combos[[b]][[c]] <- lapply(vars_diff[[b]][[c]], 
                                         function(x) append( parent_vars, x))
           }
          }
      
        # make a list to contain child models
        child_fit <- vector("list", length(child_combos))
      
        # make a list to contain child AIC
        child_fit_aic <- vector("list", length(child_combos))
      
        # models retained after comparison to parent
        child_retain <- list()
      
      for(b in seq_along(child_combos)){
        
      child_fit[[b]] <- vector("list", length(child_combos[[b]]))
      child_fit_aic[[b]] <- vector("list", length(child_combos[[b]]))
      
        for(c in seq_along(child_combos[[b]])){
        
        # fit child models for each parent model
        child_fit[[b]][[c]] <- lapply(child_combos[[b]][[c]], fit_model)
        
        # calculate AIC for each child model
        child_fit_aic[[b]][[c]] <- lapply(child_fit[[b]][[c]], AIC)
        
        }
      }
        # find minimum AIC for each group
        child_min <- vector("list", length(child_fit_aic))
        for (b in seq_along(child_fit_aic)) {
        child_min[[b]] <- sapply(child_fit_aic[[b]], function(aic_list)
      min(as.numeric(aic_list))
    )
  }
  
        
        extract_child_aic <- child_fit_aic
  for (b in seq_along(child_fit_aic)) {
    for (c in seq_along(child_fit_aic[[b]])) {

      for (j in seq_along(child_fit_aic[[b]][[c]])) {
        aic_value <- as.numeric(child_fit_aic[[b]][[c]][[j]])
        min_value <- child_min[[b]][c]
        parent_aic <- extract_aic[[b]][c]

        if (aic_value <= (min_value + delta) &&
            aic_value <= (parent_aic - epsilon)) {

          extract_child_aic[[b]][[c]][[j]] <- aic_value
        } else {
          extract_child_aic[[b]][[c]][[j]] <- NA
        }
      }
    }
  }
        
     extract_fit <- vector("list", length(child_fit))
     extract_combos <- vector("list", length(child_fit))
     extract_aic <- vector("list", length(child_fit))
        
        for (b in seq_along(child_fit)) {
    extract_fit[[b]] <- vector("list", length(child_fit[[b]]))
    extract_combos[[b]] <- vector("list", length(child_fit[[b]]))
    extract_aic[[b]] <- vector("list", length(child_fit[[b]]))

    for (c in seq_along(child_fit[[b]])) {
      keep_idx <- which(!is.na(unlist(extract_child_aic[[b]][[c]])))

      extract_fit[[b]][[c]] <- child_fit[[b]][[c]][keep_idx]
      extract_combos[[b]][[c]] <- child_combos[[b]][[c]][keep_idx]
      extract_aic[[b]][[c]] <- unlist(extract_child_aic[[b]][[c]])[keep_idx]
    }
  }
    
     frontiers[[k]] <- extract_combos
     aic_by_model[[k]] <- extract_aic
     
  k <- k + 1
      }     
    }
  
  meta <- list("Dimensions" = K, "Epsilon" = epsilon, "Delta" = delta, "Limit_For_Retention" = L, "Model Type" = model_type)
  
  return(list(
  path_forest = list(
    frontiers = frontiers,
    aic_by_model = aic_by_model,
    meta = meta)
))
  
}
           
        
```
        
     
```{r}
X <- adult[,1:14]
response <- adult[,15]
adult$NA. <- as.factor(adult$NA.)
response <- 

path_forest <- build_paths(X = adult, response = "NA.")
build_paths <- function(X, response, K = 5, epsilon = 10, delta = 200, L = 25, model_type = NULL) {

  
  # --- Auto-detect model type ---
  detect_model_type <- function(data, response_name) {
  y <- data[[response_name]]

  if (is.factor(y) || length(unique(y)) == 2) return("logistic")
  if (is.numeric(y)) return("linear")
  stop("Cannot detect model type automatically.")
}

  if (is.null(model_type)) {
    model_type <- detect_model_type(X, response)
    cat("Detected model type:", model_type, "\n")
  }
  
  predictors <- colnames(X)
  predictors <- setdiff(predictors, response)  # exclude response

  # --- Model fitting helper ---
  fit_model <- function(vars) {
    formula_str <- paste(response, "~", ifelse(length(vars) == 0, "1", paste(vars, collapse = "+")))
    if (model_type == "linear") {
      return(lm(as.formula(formula_str), data = X))
    } else {
      return(glm(as.formula(formula_str), data = X, family = binomial))
    }
  }

  # --- Initialize storage ---
  frontiers <- list()
  aic_by_model <- list()

  # --- Level 1: single-variable models ---
  start_fit <- list()
  start_aic <- numeric(length(predictors))

  for (i in seq_along(predictors)) {
    suppressWarnings({
      start_fit[[i]] <- try(fit_model(predictors[i]), silent = TRUE)
    })
    if (!inherits(start_fit[[i]], "try-error")) {
      start_aic[i] <- AIC(start_fit[[i]])
    } else {
      start_fit[[i]] <- NULL
      start_aic[i] <- NA
    }
  }

  # Save first frontier
  frontiers[[1]] <- lapply(seq_along(predictors), function(i) list(vars = predictors[i], fit = start_fit[[i]], aic = start_aic[i]))
  aic_by_model[[1]] <- start_aic

  # --- Loop over higher dimensions ---
  current_frontier <- frontiers[[1]]

  for (k in 2:K) {

    all_children <- list()
    all_children_aic <- numeric(0)

    for (parent in current_frontier) {
      parent_vars <- parent$vars
      parent_aic  <- parent$aic

      remaining <- setdiff(predictors, parent_vars)
      child_list <- list()
      child_aics <- numeric(0)

      for (v in remaining) {
        new_vars <- c(parent_vars, v)
        fit <- try(fit_model(new_vars), silent = TRUE)
        if (!inherits(fit, "try-error")) {
          aic <- AIC(fit)
          child_list <- append(child_list, list(list(vars = new_vars, fit = fit, aic = aic)))
          child_aics <- c(child_aics, aic)
        }
      }

      # Option A filtering
      if (length(child_aics) > 0) {
        best_child_aic <- min(child_aics, na.rm = TRUE)
        keep_idx <- which((child_aics - best_child_aic <= delta) & (parent_aic - child_aics > epsilon))
        if (length(keep_idx) > 0) {
          all_children <- append(all_children, child_list[keep_idx])
          all_children_aic <- c(all_children_aic, child_aics[keep_idx])
        }
      }
    }

    # Deduplicate by variable set
    if (length(all_children) > 0) {
      keys <- sapply(all_children, function(m) paste(sort(m$vars), collapse = "_"))
      all_children <- all_children[!duplicated(keys)]
      all_children_aic <- sapply(all_children, function(m) m$aic)

      # Keep top L by AIC if too many
      if (length(all_children) > L) {
        idx <- order(all_children_aic)[1:L]
        all_children <- all_children[idx]
      }
    }

    # Save this level
    frontiers[[k]] <- all_children
    aic_by_model[[k]] <- sapply(all_children, function(m) m$aic)
    current_frontier <- all_children
  }

  meta <- list(Dimensions = K, Epsilon = epsilon, Delta = delta, Limit_For_Retention = L, Model_Type = model_type)

  return(list(
    path_forest = list(
      frontiers = frontiers,
      aic_by_model = aic_by_model,
      meta = meta
    )
  ))
}


```
     
     
   
        
 
          
        }
      }
    }  
  
   child_retain <- list()

for (b in seq_along(child_fit_aic)) {

  parent_aic <- start_models$AIC[b]
  child_aics <- child_fit_aic[[b]]

  for (c in seq_along(child_aics)) {

    child_aic <- child_aics[[c]]   # extract numeric AIC

    if (child_aic > (parent_aic - delta) &&
        child_aic < (parent_aic + delta)) {
      
      child_retain[[b]][[c]] <- list(
           fit   = child_fit[[b]][[c]],
        combo = child_combos[[b]][[c]],
        parent = b,
        child = c
      )
      
    }
  }
}
      
      

      child_retain[[length(child_retain) + 1]] <- list(
        fit   = child_fit[[b]][[c]],
        combo = child_combos[[b]][[c]],
        parent = b,
        child = c
      )
    }
    }
  
  path_forest <- list("frontiers" = list(start_models, )), aic_by_model)
}
   
      
      
############# left off here on Monday
  
      
      
      remaining_vars <- setdiff(predictors, current_vars)
      if (length(remaining_vars) == 0) next

      candidate_models <- list()
      for (v in 1:length(remaining_vars)) {
        new_vars <- c(current_vars, remaining_vars[v])
        suppressWarnings({
          fit <- try(fit_model(new_vars), silent = TRUE)
        })
        if (inherits(fit, "try-error")) next
        candidate_models[[v]] <- list(variables = new_vars, AIC = AIC(fit))
      }

      if (length(candidate_models) == 0) next

      # Evaluate improvement
      aic_values <- sapply(candidate_models, function(x) x$AIC)
      best_aic <- min(aic_values)
      improved <- candidate_models[aic_values < m$AIC - epsilon]
      near_ties <- improved[aic_values[aic_values < m$AIC - epsilon] <= best_aic + delta]

      # Keep all near-ties as new models for next iteration
      if (length(near_ties) > 0) {
        new_models <- c(new_models, near_ties)
      
    }

    # Stop if no further improvements
    if (length(new_models) == 0 || step >= K) {
      cat("No further AIC improvement. Stopping at step", step, "\n")
      break
    }

    # Optionally limit total number of models
    if (length(new_models) > L) {
      new_models <- new_models[order(sapply(new_models, `[[`, "AIC"))[1:L]]
    }

    # Print *this generation* of models
    cat("Number of models created:", length(new_models), "\n")
    for (i in seq_along(new_models)) {
      cat(" Model", i, ":", paste(new_models[[i]]$variables, collapse = ", "),
          "| AIC =", round(new_models[[i]]$AIC, 3), "\n")
    }

    # Update active models for next iteration and record them all
    models <- new_models
    all_models <- c(all_models, new_models)
    k <- k + 1
    start_vars
    
    }
}

  # Deduplicate models (same variables in different order)
  unique_keys <- vapply(all_models, function(m) paste(sort(m$variables), collapse = "+"), "")
  all_models <- all_models[!duplicated(unique_keys)]

  return(all_models)
}

build_paths(data = adult[,1:14], response = adult[,15], K = 5, epsilon = 10, delta = 200, L = 25,
                        model_type = NULL)

```

# updated build paths
```{r}
# how is nimra testing the code?
multi_path_forward(data = adult[,1:14], response = adult[,15])
multi_path_forward <- function(data, response,
                               K = 5, epsilon = 1e-6, delta = 2, L = 25,
                               model_type = NULL) {

  # --- Local helper: detect model type (not exported) -----------------------
  detect_model_type <- function(data, response) {
    y <- data[[response]]
    if (is.factor(y) && nlevels(y) == 2) return("logistic")
    if (is.logical(y)) return("logistic")
    if (is.numeric(y)) {
      uy <- unique(stats::na.omit(y))
      if (length(uy) <= 2 && all(uy %in% c(0, 1))) return("logistic")
    }
    "linear"
  }

  # --- Auto-detect model type if needed ------------------------------------
  if (is.null(model_type)) {
    model_type <- detect_model_type(data, response)
    cat("Detected model type:", model_type, "\n")
  } else {
    model_type <- match.arg(tolower(model_type), c("linear", "logistic"))
  }

  predictors <- setdiff(names(data), response)

  # --- Fit function ---------------------------------------------------------
  fit_model <- function(vars) {
    formula_str <- paste(
      response, "~",
      ifelse(length(vars) == 0, "1", paste(vars, collapse = "+"))
    )
    f <- stats::as.formula(formula_str)

    if (model_type == "linear") {
      stats::lm(f, data = data)
    } else {
      stats::glm(f, data = data, family = stats::binomial())
    }
  }

  # --- Initialize -----------------------------------------------------------
  start_fit <- fit_model(character())
  start_aic <- stats::AIC(start_fit)

  models <- list(list(variables = character(), AIC = start_aic))
  frontiers <- list()
  aic_by_model <- list()

  step <- 1L
  repeat {
    new_models <- list()
    model_hash <- character()

    for (m in models) {
      current_vars <- m$variables
      remaining_vars <- setdiff(predictors, current_vars)
      if (length(remaining_vars) == 0L) next

      candidate_models <- list()
      for (v in remaining_vars) {
        new_vars <- c(current_vars, v)
        key <- paste(sort(new_vars), collapse = ",")

        if (key %in% model_hash) next

        fit <- try(suppressWarnings(fit_model(new_vars)), silent = TRUE)
        if (inherits(fit, "try-error")) next

        aic_val <- stats::AIC(fit)
        if (!is.finite(aic_val)) next

        candidate_models[[key]] <- list(variables = new_vars, AIC = aic_val)
        model_hash <- c(model_hash, key)
      }

      if (length(candidate_models) == 0L) next

      aic_values <- vapply(candidate_models, function(x) x$AIC, numeric(1))
      best_aic <- min(aic_values)

      # Keep only near-best children
      selected <- candidate_models[aic_values <= best_aic + delta]

      # Only if parent improves by > Îµ
      if (best_aic < m$AIC - epsilon) {
        new_models <- c(new_models, selected)
      }
    }

    if (length(new_models) == 0L || step >= K) break

    # Sort by AIC before truncating
    aics <- vapply(new_models, function(x) x$AIC, numeric(1))
    ord <- order(aics)
    new_models <- new_models[ord]

    # Keep best L
    new_models <- new_models[seq_len(min(L, length(new_models)))]

    # Save frontier
    frontiers[[step]] <- new_models

    # Save AIC dictionary
    for (nm in new_models) {
      key <- paste(sort(nm$variables), collapse = ",")
      aic_by_model[[key]] <- nm$AIC
    }

    models <- new_models
    step <- step + 1L
  }

  list(
    path_forest = frontiers,
    aic_by_model = aic_by_model,
    meta = list(K = K, epsilon = epsilon, delta = delta, L = L,
                model_type = model_type)
  )
}

```


3.3 Plausible Models
```{r}
plausible_models
```






