---
title: "Multi-Path Selection Algorithm: Group 7"
author: "Nimra Ismail, Savannah Rascon, Lilley Brookshire"
output:
  html_document:
    css: autumn.css
    toc: true
    toc_depth: 3
    toc_float: true
    fig_caption: true
    highlight: tango    # Colorful syntax highlighting
vignette: >
  %\VignetteIndexEntry{Multi-Path AIC Model Selection (Breast Cancer Classification)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```
# Repository 

The repository that contains the project with our test files and the project for our final package can be found here: <https://github.com/R-4-Data-Science/Final-Project-Group-7/tree/main>

The repository is named Final_Project_Group_7. 

The project that contains the documentation for our package is in the folder FinalProjectNimra. 

# 5. HTML with Runnable Examples

This section demonstrates runnable examples that illustrate how the **multi-path AIC model selection** algorithm works for both regression families: **Gaussian (linear regression)** and **Binomial (logistic regression)**. These examples use synthetic data to ensure that the package’s functions behave as expected. 

Initially, we show base R–style demonstrations (Sections 5.1 and 5.2) to confirm that the AIC-based model comparisons are functioning properly. Then, in Section 5.3, we demonstrate how to use the actual package workflow to perform a full end-to-end analysis.

---

## 5.1 Linear Regression (Gaussian)

This subsection illustrates the concept of **AIC-based model comparison** using **base R functions** on synthetic continuous data. We simulate Gaussian data with a known linear relationship and compare several simple regression models to demonstrate how AIC penalizes unnecessary complexity while rewarding better fit.

```{r linear-baseR, echo=TRUE}

# Base R Linear Regression Example (Gaussian)

set.seed(1)
n <- 120; p <- 8

# Simulate predictors
X <- matrix(rnorm(n * p), n, p)
colnames(X) <- paste0("x", 1:p)

# Define the true relationship
beta <- c(2, -1.5, 0, 0, 1, rep(0, p - 5))
y <- X %*% beta + rnorm(n, sd = 1)

# Combine into a data frame
df <- data.frame(y, X)

# Fit an intercept-only model
fit0 <- lm(y ~ 1, data = df)
aic0 <- AIC(fit0)

# Fit single-variable models to compare AICs
fits <- lapply(1:p, function(j) lm(as.formula(paste("y ~", colnames(X)[j])), data = df))
aics <- sapply(fits, AIC)

# Display top 5 models with lowest AIC
aic_results <- data.frame(Variable = colnames(X), AIC = aics)
aic_results <- aic_results[order(aic_results$AIC), ]
head(aic_results, 5)
```

The table shows the five predictors with the lowest AIC values from the single-variable linear regression models. Among them, `x1`, `x2`, and `x5` have the smallest AIC scores (535.5, 556.4, and 581.5, respectively), indicating that these predictors provide the best model fit with the least complexity penalty.

Because the synthetic data were generated with a true underlying relationship involving `x1`, `x2`, and `x5`, the AIC-based comparison correctly identifies these as the most informative variables. Predictors such as `x3` and `x7`, while still contributing modestly, show higher AIC values, meaning they offer less improvement in fit relative to the increase in model complexity.

## 5.2 Logistic Regression (Binomial)

In this subsection, we illustrate AIC-based model comparison for a binary classification problem using **base R** logistic regression. We generate binary data from a known logistic model and compare candidate models containing individual predictors. This helps visualize how AIC extends naturally from Gaussian to Binomial models for classification.

```{r logistic-baseR, echo=TRUE}

# Base R Logistic Regression Example (Binomial)

set.seed(2)
n <- 200; p <- 6

# Simulate predictors

Xb <- matrix(rnorm(n * p), n, p)
colnames(Xb) <- paste0("x", 1:p)

# Generate binary outcome based on a logistic function

linpred <- 1.2 * Xb[,1] - 1 * Xb[,2] + 0.8 * Xb[,5]
prob <- 1 / (1 + exp(-linpred))
ybin <- rbinom(n, 1, prob)

# Combine into a data frame

dfb <- data.frame(y = ybin, Xb)

# Fit intercept-only model

fit0 <- glm(y ~ 1, family = binomial(), data = dfb)
aic0 <- AIC(fit0)

# Fit single-variable models

fits1 <- lapply(1:p, function(j) glm(as.formula(paste0("y ~ ", colnames(Xb)[j])),
family = binomial(), data = dfb))
aics1 <- sapply(fits1, AIC)

# Display top 5 models with lowest AIC

aic_results_log <- data.frame(Variable = colnames(Xb), AIC = aics1)
aic_results_log <- aic_results_log[order(aic_results_log$AIC), ]
head(aic_results_log, 5)
```

The table summarizes the AIC values for logistic regression models fitted with each predictor individually. The variables `x1`, `x2`, and `x5` have the lowest AIC scores (241.1, 259.7, and 264.5, respectively), indicating that these predictors provide the best trade-off between model fit and simplicity.

This aligns with the way the synthetic data were generated, where `x1`, `x2`, and `x5` were intentionally set as influential predictors in the logistic model. Their lower AIC values show that these variables most effectively explain the variation in the binary outcome.

## 5.3 Example Usage

This section demonstrates the **complete workflow** using the functions implemented in the `FinalProjectNimra` package.

The purpose of this section is to replace the original placeholder example from the assignment (which used `build_paths()`, `stability()`, and `plausible_models ()`).

We show both linear and logistic regression examples, and this section confirms that the package functions integrate properly and produce interpretable, stable results for both regression families.

```{r install-and-load}
# Install the package (uncomment if not already installed)
# install.packages("remotes")
# remotes::install_github("R-4-Data-Science/Final-Project-Group-7/FinalProjectNImra")

# Load the package
library(FinalProjectNimra)
```

Our chosen defaults for the interal workings of our functions were:
  - K (maximum number of steps) = 5: default of 5 levels for the iterations allows for thorough filtering but avoids long run time.
  - $\epsilon$ (minimum AIC improvement from parent model) = .000001: keeping this smalls allows us to retain models that improve even a small amount from their parent.
  - $\delta$ (AIC tolerance for near ties in children) = 2: this means that only children that perform essentially equally best are retained.
  - $L$ (max number of models kept per level) = 25: this allows for a pool of good models to be kept at each level, but prevents clutter/ long run time.
  - $B$ (number of resamples for stability) = 100: the bootstrap resampling is most effective if the number of resamples is high to improve accuracy, but you must also balance run time, and 100 has worked well.
  - $\Delta$ (AIC tolerance for plausibility) = 2: same as $\delta$, this ensures that only models that are the very best and very close are retained.
  - $\tau$ (minimum average stability) = 0.6: this metric ensures that only variables that appear in the majority of models, and therefore are the most stable, are prioritized.
  
  
## Example 1 – Linear Regression (Gaussian)

We first demonstrate the multi-path AIC workflow on simulated Gaussian data.
The goal is to recover the true underlying predictors while accounting for model uncertainty and stability.

```{r}
set.seed(123)

# Simulate Gaussian data
n <- 120; p <- 8
X <- matrix(rnorm(n * p), n, p)
beta <- c(2, -1.5, 0, 0, 1, rep(0, p - 5))
y <- X %*% beta + rnorm(n, sd = 1)
df <- as.data.frame(cbind(y, X))
colnames(df) <- c("y", paste0("x", 1:p))

# Run the full procedure

# multi-path forward selection
path_forest <- build_paths(
  X = df, 
  response = "y", 
  K = 5,
  epsilon = .000001, 
  delta = 2, 
  L = 25, 
  model_type = NULL
  )

# stability with resampling
stability_scores <- stability(
  X = df, 
  response = "y", 
  B = 100, 
  K = 5, 
  epsilon = 1e-6, 
  delta = 2, 
  L = 25, 
  model_type = NULL
  )

# select plausible models
plausible <- plausible_models(
  full_data_models = path_forest$path_forest$frontiers, 
  stability_df = stability_scores,
  delta = 2,
  tau = 0.6
  )

plausible

AIC_table <- as.matrix(c(plausible[[1]]$aic, plausible[[2]]$aic, plausible[[3]]$aic, plausible[[4]]$aic), nrow = 1, ncol = 4)
rownames(AIC_table) <- c("model 1", "model 2", "model 3", "model 4")
colnames(AIC_table) <- c("Final AIC Values")
AIC_table
boxplot(AIC_table, main = "Final AIC Values")
```

The multi-path AIC procedure identified plausible and stable models that all included `X1`, `X2`, `X5` and `X7`. 

## Example 2 – Logistic Regression (Binomial)

Next, we apply the same approach to synthetic binary data generated from a logistic model.
This demonstrates how the same function can handle classification problems.

```{r}
# Simulate binary logistic data
n <- 200; p <- 6
Xb <- matrix(rnorm(n * p), n, p)
colnames(Xb) <- paste0("x", 1:p)

# Define the true logistic relationship
linpred <- 1.2 * Xb[,1] - 1 * Xb[,2] + 0.8 * Xb[,5]
prob <- 1 / (1 + exp(-linpred))
ybin <- rbinom(n, 1, prob)

# Combine into a data frame
dfb <- as.data.frame(cbind(y = ybin, Xb))

# Run the full procedure

# multi-path forward selection
path_forest_glm <- build_paths(
  X = dfb, 
  response = "y", 
  K = 5,
  epsilon = .000001, 
  delta = 2, 
  L = 25, 
  model_type = NULL
  )

# stability with resampling
stability_scores_glm <- stability(
  X = dfb, 
  response = "y", 
  B = 100, 
  K = 5, 
  epsilon = 1e-6, 
  delta = 2, 
  L = 25, 
  model_type = NULL
  )

# select plausible models
plausible_glm <- plausible_models(
  full_data_models = path_forest_glm$path_forest$frontiers, 
  stability_df = stability_scores_glm,
  delta = 2,
  tau = 0.6
  )

plausible_glm

AIC_table_glm <- as.matrix(c(plausible_glm[[1]]$aic), nrow = 1, ncol = 1)
rownames(AIC_table_glm) <- "model 1"
colnames(AIC_table_glm) <- c("Final AIC Values")
AIC_table_glm
boxplot(AIC_table_glm, main = "Final AIC Values")
```

The multi-path AIC procedure identified one plausible and stable model consisting of predictors `X1`, `X2`, and `X5` (AIC = 203.411, Avg. Stability = 1). These variables correspond exactly to the true predictors used to generate the binary outcome, confirming accurate recovery of the underlying data structure.

All three predictors (`X1`, `X2`, `X5`) have a stability score of 1, indicating consistent selection of the correct variables across all bootstrap samples.

**Interpretation:**

These examples demonstrate that the `FinalProjectNimra` package successfully:

+ Explores multiple near-optimal AIC paths (controlled by δ = 1).

+ Estimates variable stability across bootstrap samples (B = 20).

+ Filters plausible models using AIC tolerance (Δ = 2 by default) and stability threshold (τ = 0.6).

The results verify that both linear and logistic regression families are supported and produce interpretable, stable model selections.

# Appendix
## Links for chats with ChatGPT
<https://chatgpt.com/share/693361bd-64c4-800f-b3a3-a2982dedffa5>
<https://chatgpt.com/share/693361d0-dcb8-800f-95d3-fa6da5957fe5>
<https://chatgpt.com/share/693361ea-fd60-800f-894d-a4537e4b80b8>

## Other sourses
Chapter 5,6: <https://smac-group.github.io/ds/section-control.html>
Chapter 25: <https://r4ds.hadley.nz/functions.html>
<https://search.r-project.org/R/refmans/stats/html/lm.html>

