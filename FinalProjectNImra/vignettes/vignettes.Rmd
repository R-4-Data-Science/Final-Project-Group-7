---
title: "Multi-Path AIC Model Selection"
author: "Nimra Ismail"
output:
  html_document:
    theme: yeti
    toc: false            # disable default TOC
    toc_depth: 3
    toc_float: false
    number_sections: true
    css: custom.css
    fig_caption: true
    highlight: tango    # Colorful syntax highlighting
vignette: >
  %\VignetteIndexEntry{Multi-Path AIC Model Selection (Breast Cancer Classification)}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r toc, echo=FALSE}
cat('<div id="toc">')
cat('</div>')
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
library(FinalProjectNimra)
library(mlbench)
library(dplyr)
library(caret)
set.seed(123)
```

# Introduction

This vignette demonstrates the use of the **FinalProjectNimra** R package for performing a complete model selection pipeline based on the **multi-path AIC procedure**.  
The package implements an advanced model selection algorithm that explores multiple near-optimal model paths, evaluates variable stability via bootstrap resampling, and filters plausible models based on both AIC and variable stability.

The vignette illustrates:

1. The workflow of the algorithm (multi-path selection, stability estimation, plausible model filtering).  
2. Its application on the **Breast Cancer Wisconsin dataset** for a **logistic regression** task.  
3. Evaluation of **model accuracy and diagnostic performance** metrics.

# Dataset

We use the **Breast Cancer Wisconsin** dataset for binary classification.  
The goal is to distinguish **malignant (1)** vs **benign (0)** tumors based on several cell-nuclei features.

```{r data}
data("BreastCancer", package = "mlbench")
df <- na.omit(BreastCancer)
df$Class <- ifelse(df$Class == "malignant", 1, 0)
df <- df %>% mutate(across(where(is.factor), as.numeric))
head(df)
```

The dataset contains predictors describing characteristics of cell nuclei and a binary target variable indicating whether the tumor is **malignant** or **benign**.

## Train/Test Split

We split the data into **70% training** and **30% testing** subsets to evaluate model performance on unseen data.

```{r split}
train_index <- createDataPartition(df$Class, p = 0.7, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
dim(train_data); dim(test_data)
```

This ensures that both subsets maintain class balance for fair model evaluation.

# Multi-Path AIC Search

We now run the **multi-path model selection pipeline** from our package on the training set.  
The parameters used are summarized below:

| Parameter | Description | Value Used |
|------------|--------------|-------------|
| K | Number of paths explored | 4 |
| B | Bootstrap replicates for stability estimation | 50 |
| δ (delta) | AIC threshold for near-optimal models | 1 |
| τ (tau) | Stability cutoff for plausible model inclusion | 0.6 |

> **Note:**

These values provide a balanced trade-off between computational efficiency and exploration depth. The AIC tolerance (`delta = 1`) ensures that near-optimal models are retained, while the stability threshold (`tau = 0.6`) filters predictors that consistently appear in at least 60% of bootstrap samples. Parameters `eps` and `L` are left at default values (`eps = 1e-6`, `L = 50`), which are sufficient for this dataset size.
.

```{r search}
res_logistic <- multi_path_AIC_procedure(
  train_data,
  response = "Class",
  K = 4,
  B = 50,
  delta = 1,
  tau = 0.6
)

res_logistic$plausible_models
```

δ = 1 defines models whose AIC values are within one unit of the minimum, meaning they are statistically indistinguishable from the best model.

# Stability Visualization

The variable stability plot shows how frequently each predictor appears across bootstrap samples. High stability indicates robust predictors that consistently contribute to good model fits.

```{r plot, fig.cap="Figure 1: Variable stability scores across bootstrap samples."}
plot_stability(res_logistic$stability)
```

***Interpretation:***

From Figure, Bare.nuclei and Cell.size exhibit the highest stability, each appearing in the majority of bootstrap-selected models. This suggests that these predictors are the most reliable and consistently associated with breast cancer classification outcomes.

Variables such as  Cl.thickness and Cell.shape show moderate stability, implying that they may contribute to the model in some bootstrap samples but are not universally strong predictors.

On the other hand, features like Bl.cromatin, Marg.adhesion, Mitoses, Normal.nucleoli, Id, and Epith.c.size demonstrate low stability, indicating that they are less influential and may represent noise or dataset-specific variability.

Overall, the stability plot highlights Bare.nuclei and Cell.size as the most critical and reproducible predictors across resampled models.


# Model Evaluation on Test Data

We now evaluate the **most stable plausible model** on the held-out test set. The model is fitted on the training data using the predictors identified from the multi-path AIC procedure and then validated on the test data.

After performing the multi-path AIC search and stability estimation, we identify the final plausible models using both AIC and stability-based filtering criteria. This is achieved internally through the function `select_plausible_models()`, which applies two key thresholds: the **AIC tolerance (Δ)** and the **minimum average stability (τ)**.

Although **Δ** (Delta) is not explicitly specified in our vignette code, it is automatically applied as the argument `delta_AIC = 2` inside the `select_plausible_models()` function. By default, this threshold retains all models whose AIC values are within **two units of the minimum AIC**, which is the standard guideline for identifying statistically indistinguishable models in terms of fit quality [(Burnham & Anderson, 2002)](https://doi.org/10.1007/b97636). Thus, the plausible model selection process inherently respects this Δ = 2 criterion even without user specification.

Similarly, the stability threshold **τ = 0.6** is used to filter models based on the consistency of variable selection across bootstrap resamples. Variables that appear in at least 60% of resampled models are retained as stable predictors. This threshold balances parsimony and robustness by emphasizing predictors that contribute reliably to model performance across sampling variability [(Meinshausen & Bühlmann, 2010)](https://doi.org/10.1214/09-AOS687).

```{r eval}
top_model_vars <- res_logistic$plausible_models[[1]]$variables
formula_str <- as.formula(paste("Class ~", paste(top_model_vars, collapse = "+")))
final_fit <- glm(formula_str, data = train_data, family = binomial)

# Predict on test data
pred_probs <- predict(final_fit, test_data, type = "response")
pred_class <- ifelse(pred_probs > 0.5, 1, 0)

# Confusion matrix and performance metrics
conf_matrix <- table(Predicted = pred_class, Actual = test_data$Class)
conf_matrix

accuracy <- mean(pred_class == test_data$Class)
sensitivity <- conf_matrix["1","1"] / sum(conf_matrix[,"1"])
specificity <- conf_matrix["0","0"] / sum(conf_matrix[,"0"])
FDR <- 1 - specificity
DOR <- (sensitivity / (1 - sensitivity)) / ((1 - specificity) / specificity)

data.frame(accuracy, sensitivity, specificity, FDR, DOR)
```

***Interpretation:***

The confusion matrix above summarizes the classification performance of the logistic model on the unseen test data, comparing predicted versus actual tumor classes. The confusion matrix shows **excellent classification** performance on the test data.

+ **Accuracy** = 0.9608 → Out of 204 test samples, 196 were correctly classified, yielding an overall accuracy of 96.1%.

+ **Sensitivity** = 0.924 → The model correctly identifies 92.4% of malignant tumors, demonstrating strong detection ability for positive cases.

+ **Specificity** = 0.978 → The model correctly identifies 97.8% of benign tumors, meaning very few benign samples were misclassified as malignant.

+ **FDR** = 0.0217 → Only about 2% of predicted malignant cases were actually benign, showing that false positives are minimal.

+ **DOR** = 549 → The extremely high Diagnostic Odds Ratio indicates outstanding discriminative power, confirming the model’s ability to separate malignant and benign cases with high reliability.

Overall, these results confirm that the multi-path AIC–selected model generalizes exceptionally well, achieving high accuracy and balanced performance across sensitivity and specificity. It effectively identifies malignant cases while maintaining very low false-positive and false-negative rates, a crucial feature for reliable medical classification.

# Reproducibility

Ensuring reproducibility is a critical step in any data analysis workflow. The following R session information records package versions and environment details used to generate this vignette. This allows other researchers to replicate the analysis exactly.

```{r session-info}
sessionInfo()
```

# Discussion

The results from the model evaluation demonstrate that the **multi-path AIC procedure** produces a highly accurate and reliable logistic regression model for breast cancer classification. By exploring multiple near-optimal model paths and assessing variable stability through bootstrap resampling, the algorithm identifies predictors that are both **statistically sound** and **biologically meaningful**.

The final model achieved:

- **Accuracy:** 0.96  
- **Sensitivity:** 0.92  
- **Specificity:** 0.98  
- **False Discovery Rate (FDR):** 0.02  
- **Diagnostic Odds Ratio (DOR):** 549  

These metrics indicate **excellent generalization performance**.  
The model correctly classified the majority of both malignant and benign cases, with **very few misclassifications** (only 8 out of 204 total samples).  

The high **sensitivity** shows that the model effectively identifies malignant tumors — a crucial property for medical diagnostic models where false negatives can have serious consequences. At the same time, the **specificity** close to 98% ensures that benign cases are rarely misclassified as malignant, minimizing unnecessary concern or follow-up procedures.

The **DOR value of 549** further confirms the model’s **outstanding discriminative ability** ,values above 100 typically indicate a strong distinction between positive and negative classes, while this result shows near-perfect separation.  

Additionally, the earlier **stability analysis** revealed that features such as **Bare.nuclei** and **Cell.size** were consistently selected across bootstrap resamples, reinforcing their importance as **robust and reproducible predictors**. This stability, combined with the high predictive performance, demonstrates that the **multi-path AIC approach** successfully balances **model parsimony**, **interpretability**, and **accuracy**.

**Summary:**  
The multi-path AIC–based selection framework provides a powerful and interpretable solution for identifying reliable predictors of breast cancer malignancy.  

It ensures that the final model is not only statistically optimal (in terms of AIC) but also **clinically meaningful**, achieving strong predictive performance with stable and biologically relevant variables.

